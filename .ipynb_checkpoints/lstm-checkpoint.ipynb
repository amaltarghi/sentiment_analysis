{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata \n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "import unicodedata \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "movies_data = pd.read_table(\"train.tsv\")\n",
    "movies_data.shape\n",
    "movies_data[\"Sentiment\"].unique()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_test = pd.read_table(\"test.tsv\")\n",
    "movie_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_data['Phrase'] = (movies_data['Phrase'].str.lower()\n",
    "              .str.decode('utf-8')\n",
    "              .map(lambda x: unicodedata.normalize('NFKD', x))\n",
    "              .str.encode('ascii', 'ignore'))\n",
    "\n",
    "movie_test['Phrase'] = (movie_test['Phrase'].str.lower()\n",
    "              .str.decode('utf-8')\n",
    "              .map(lambda x: unicodedata.normalize('NFKD', x))\n",
    "              .str.encode('ascii', 'ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [\"Phrase\", \"Sentiment\"]\n",
    "movies_data_new =movies_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_data_new.to_csv(\"train.csv\", index= False)\n",
    "movie_test.to_csv(\"test.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66293\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"test.csv\", 'r') as file: \n",
    "    test = list(csv.reader(file))\n",
    "\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"train.csv\", 'r') as file: \n",
    "    reviews = list(csv.reader(file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_text(reviews, score):\n",
    "    # Join together the text in the reviews for a particular tone.\n",
    "    #We lowercase to avoid \"Not\" and \"not\" being seen as different words, for example.\n",
    "\n",
    "    return \"\\n\".join([r[0].lower() for r in reviews if r[1] == str(score)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_text = get_text(reviews, 0)\n",
    "somewhat_negative_text = get_text(reviews, 1)\n",
    "neutral_text = get_text(reviews, 2)\n",
    "somewhat_positive_text = get_text(reviews, 3)\n",
    "positive_text = get_text(reviews, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_words(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in stop])\n",
    "    return text\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    s = ''.join([i for i in s if i not in set(string.punctuation)])\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#negative_text = stop_words(negative_text)\n",
    "#negative_text = remove_punctuation(negative_text)\n",
    "\n",
    "#positive_text = stop_words(positive_text)\n",
    "#positive_text = remove_punctuation (positive_text)\n",
    "\n",
    "#somewhat_negative_text = stop_words(somewhat_negative_text)\n",
    "#somewhat_negative_text = remove_punctuation(somewhat_negative_text)\n",
    "\n",
    "#somewhat_positive_text = stop_words(somewhat_positive_text)\n",
    "#somewhat_positive_text = remove_punctuation (somewhat_positive_text)\n",
    "\n",
    "#neutral_text = stop_words(neutral_text)\n",
    "#neutral_text = remove_punctuation (neutral_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#neutral_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"positive_text.txt\", \"w\") as text_file:\n",
    "    text_file.write(positive_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"negative_text.txt\", \"w\") as text_file:\n",
    "    text_file.write(negative_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"somewhat_negative_text.txt\", \"w\") as text_file:\n",
    "    text_file.write(somewhat_negative_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"neutral_text.txt\", \"w\") as text_file:\n",
    "    text_file.write(neutral_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"somewhat_positive_text.txt\", \"w\") as text_file:\n",
    "    text_file.write(neutral_text+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "np.random.seed(1337)  # For Reproducibility\n",
    "import multiprocessing\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from utils import *\n",
    "import glob\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import unicodedata\n",
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "import keras\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import io\n",
    "    sentences_pos = []\n",
    "    ff = \"positive_text.txt\"\n",
    "    with io.open(ff, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            sentences_pos.append(line)\n",
    "    sentences_neg = []\n",
    "    ff = \"negative_text.txt\"\n",
    "    with io.open(ff, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            sentences_neg.append(line)\n",
    "    \n",
    "    sentences_smwn = []\n",
    "    ff = \"somewhat_negative_text.txt\"\n",
    "    with io.open(ff, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            sentences_smwn.append(line)\n",
    "            \n",
    "    sentences_smwp = []    \n",
    "    ff = \"somewhat_positive_text.txt\"\n",
    "    with io.open(ff, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            sentences_smwp.append(line)\n",
    "            \n",
    "    sentences_neutral = []        \n",
    "    ff = \"neutral_text.txt\"\n",
    "    with io.open(ff, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            sentences_neutral.append(line)\n",
    "            \n",
    "            \n",
    "    X = sentences_pos+sentences_neg+sentences_smwn+sentences_neutral+sentences_smwp\n",
    "    y = [4]*len(sentences_pos)+[0]*len(sentences_neg)+[1]*len(sentences_smwn)+[2]*len(sentences_neutral) + [3]*len(sentences_smwp)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202715"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stemmering_sentences(sentence):\n",
    "    # Remove punctuation, stopword and then stemmering\n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    # tmp = unicode(sentence, errors='ignore')\n",
    "    tmp = sentence\n",
    "    doc = [stemmer.stem(word.lower()) for word in nltk.word_tokenize(tmp) if\n",
    "           (word not in punctuation) and (word not in nltk.corpus.stopwords.words('english')) and (word != 'br')]\n",
    "    return doc\n",
    "\n",
    "def stemming(X, y):\n",
    "    sentences_stem = Parallel(n_jobs=4)(delayed(stemmering_sentences)(sentence) for sentence in tqdm.tqdm(X, desc=\"stem\"))\n",
    "    return sentences_stem, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stem: 100%|██████████| 202715/202715 [01:13<00:00, 2745.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = stemming(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "vocab_dim = 10\n",
    "maxlen = 10\n",
    "n_iterations = 20 # ideally more..\n",
    "# Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. \n",
    "n_exposures = 10\n",
    "window_size = 10\n",
    "batch_size = 20\n",
    "n_epoch = 10\n",
    "input_length = 100\n",
    "cpu_count = multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine_train_test_X = terms_by_doc_train + terms_by_doc_test\n",
    "combine_train_test_X = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Word2vec model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52527863"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training a Word2vec model...')\n",
    "bigram = gensim.models.Phrases(combine_train_test_X)\n",
    "#bigram_transformer = gensim.models.Phrases(X)\n",
    "a = list(bigram[bigram[combine_train_test_X]])\n",
    "                   \n",
    "model = Word2Vec(size=vocab_dim,\n",
    "                 min_count=n_exposures,\n",
    "                 window=window_size,\n",
    "                 workers=cpu_count,\n",
    "                 iter=n_iterations)\n",
    "model.build_vocab(a)\n",
    "model.train(a)\n",
    "\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Arrays for Keras Embedding Layer...\n"
     ]
    }
   ],
   "source": [
    "gensim_dict = Dictionary()\n",
    "gensim_dict.doc2bow(model.vocab.keys(), allow_update=True)\n",
    "# gensim_dict.items() returns [(0, u\"'surpris\"), (1, u'woodi'), (2, u'yellow'),...]\n",
    "# K+1 aims at avoiding 0 as index.\n",
    "w2indx = {v: k+1 for k, v in gensim_dict.items()}\n",
    "w2vec = {word: model[word] for word in w2indx.keys()}\n",
    "# print len(model[\"surpris\"]) -> 100\n",
    "print('Setting up Arrays for Keras Embedding Layer...')\n",
    "n_symbols = len(w2indx) + 1  # adding 1 to account for 0th index\n",
    "embedding_weights = np.zeros((n_symbols + 1, vocab_dim))\n",
    "for word, index in w2indx.items():\n",
    "    embedding_weights[index, :] = w2vec[word]\n",
    "# print embedding_weights.shape -> (11405, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "terms_by_doc_train, terms_by_doc_test, y_train, y_test = train_test_split(X,y, test_size=0.1)\n",
    "X_train = []\n",
    "for doc in terms_by_doc_train:\n",
    "    new_txt = []\n",
    "    for word in doc:\n",
    "        try:\n",
    "            new_txt.append(w2indx[word])\n",
    "        except:\n",
    "            new_txt.append(0)\n",
    "    X_train.append(new_txt)\n",
    "X_test = []\n",
    "for doc in terms_by_doc_test:\n",
    "    new_txt = []\n",
    "    for word in doc:\n",
    "        try:\n",
    "            new_txt.append(w2indx[word])\n",
    "        except:\n",
    "            new_txt.append(0)\n",
    "    X_test.append(new_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "(u'X_train shape:', (182443, 20))\n",
      "(u'X_test shape:', (20272, 20))\n",
      "(u'X_train shape:', (182443,))\n",
      "(u'X_test shape:', (20272,))\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print('X_train shape:',  y_train.shape)\n",
    "print('X_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.objectives import  categorical_crossentropy\n",
    "\n",
    "def loss_fct(y_true, y_pred):\n",
    "    \n",
    "    \n",
    "    # l2 = 0.001 * (model.layers[0].W**2).sum()\n",
    "    l2 = 0\n",
    "    return categorical_crossentropy(y_true, y_pred) + l2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def my_init(shape, name=None):\n",
    "    value = np.sqrt(6/np.random.random(shape))\n",
    "    return K.variable(value, name=name)\n",
    "\n",
    "#w = np.random.normal(loc=0.0, scale=sigma/np.sqrt(nn_arch[i]), size=(nn_arch[i+1],nn_arch[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining a Simple Keras Model...\n",
      "Compiling the Model...\n",
      "Train...\n",
      "Train on 182443 samples, validate on 20272 samples\n",
      "Epoch 1/20\n",
      "182443/182443 [==============================] - 216s - loss: 0.7741 - acc: 0.3903 - val_loss: 0.6450 - val_acc: 0.3941\n",
      "Epoch 2/20\n",
      "  3820/182443 [..............................] - ETA: 219s - loss: 0.6463 - acc: 0.4055"
     ]
    }
   ],
   "source": [
    "print('Defining a Simple Keras Model...')\n",
    "model = Sequential()  # or Graph or whatever\n",
    "model.add(Embedding(input_dim=n_symbols ,\n",
    "                    output_dim=vocab_dim))\n",
    "\n",
    "                    #input_length=input_length))  # Adding Input \n",
    "model.add(Dense(64, init=my_init))\n",
    "#model.add(Dense(64, init='normal'))\n",
    "model.add(LSTM(vocab_dim))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "#model.add(Dense(1, activation='relu'))\n",
    "\n",
    "#sgd = keras.optimizers.SGD(lr=0.01, momentum=0.1, decay=0, nesterov=True)\n",
    "adam = keras.optimizers.Adam(lr=0.2, beta_1=0.2, beta_2=0.2, epsilon=0.1, decay=0.5)\n",
    "adamax = keras.optimizers.Adamax(lr=0.2, beta_1=0.2, beta_2=0.2, epsilon=0.1 ,decay=0)\n",
    "prop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0)\n",
    "\n",
    "print('Compiling the Model...')\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=prop, metrics=['accuracy'])\n",
    "\n",
    "print(\"Train...\")\n",
    "history  = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "print(\"Evaluate...\")\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Test score:', 0.60870833381998402)\n",
      "(u'Test accuracy:', 0.40709169354989488)\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAF5CAYAAAAyBjhMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAf8URpsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f865bcc8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['acc'],label = 'acc train')\n",
    "plt.plot(history.history['val_acc'],label = 'acc val')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Accuarcay\")\n",
    "plt.ylim([0.,1.])\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
